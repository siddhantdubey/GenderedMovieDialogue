{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "hOXetHkb380D",
    "outputId": "30297597-0a1c-48b0-8248-638cc2ddcc93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/Folders/Work/Research/CornellMovie/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xCBEa8g2Gk4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchtext \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9VL_aoh3HaL"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkwGy7C23OXY"
   },
   "outputs": [],
   "source": [
    "with open(root_dir + 'training_set.txt', encoding=\"charmap\") as training:\n",
    "  for line in training:\n",
    "    line = line.strip()\n",
    "    line_num, chr_id, movie_id, chr_name, chr_gender, line_text, credit = line.split(\"+++$+++\")\n",
    "    if(chr_gender.strip().lower() == \"m\"):\n",
    "      Y_train.append(0)\n",
    "      X_train.append(line_text.strip())\n",
    "    elif(chr_gender.strip().lower() == \"f\"):\n",
    "      Y_train.append(1)\n",
    "      X_train.append(line_text.strip())\n",
    "\n",
    "with open(root_dir + 'test_set.txt', encoding=\"charmap\") as test:\n",
    "  for line in test:\n",
    "    line = line.strip()\n",
    "    line_num, chr_id, movie_id, chr_name, chr_gender, line_text, credit = line.split(\"+++$+++\")\n",
    "    if(chr_gender.strip().lower() == \"m\"):\n",
    "      Y_test.append(0)\n",
    "      X_test.append(line_text.strip())\n",
    "\n",
    "    elif(chr_gender.strip().lower() == \"f\"):\n",
    "      Y_test.append(1)\n",
    "      X_test.append(line_text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBxJ3qOa9M3t"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-DPBPPu-DFl"
   },
   "outputs": [],
   "source": [
    "X_test_counts = count_vect.fit_transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNX_o-vg5mEJ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0svoWp5AXx_"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANKW2QPcNBt2"
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(X_train)):\n",
    "  if(len(X_train[i]) > 0):\n",
    "    answer = True \n",
    "  else:\n",
    "    indices.append(i)\n",
    "\n",
    "for index in sorted(indices, reverse=True):\n",
    "    del X_train[index]\n",
    "    del Y_train[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vvh56ULGOzoq"
   },
   "outputs": [],
   "source": [
    "y_indexes = []\n",
    "for i in range(len(X_test)):\n",
    "  if(len(X_test[i]) > 0):\n",
    "    answer = True\n",
    "  else:\n",
    "    y_indexes.append(i)\n",
    "\n",
    "for index in sorted(y_indexes, reverse=True):\n",
    "  del X_test[index]\n",
    "  del Y_test[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DMqz7C4fAraN",
    "outputId": "bbc799c8-b8f2-4a2b-b737-b5675fe8c3fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = X_train + X_test\n",
    "Y = Y_train + Y_test\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X, Y = oversample.fit_resample(np.array(X).reshape(-1,1), Y)\n",
    "\n",
    "a = []\n",
    "for phrase in X:\n",
    "    a.append(phrase[0].strip())\n",
    "X = a\n",
    "df['text'] = X\n",
    "df['target'] = Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUZlhbqngsh9"
   },
   "outputs": [],
   "source": [
    "def get_top_data(top_n = 30000):\n",
    "  top_data_df_male = df[df['target'] == 0].head(top_n)\n",
    "  top_data_df_female = df[df['target'] == 1].head(top_n)\n",
    "  data_df_small = pd.concat([top_data_df_male, top_data_df_female])\n",
    "  return data_df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FIRn6eAg2qO"
   },
   "outputs": [],
   "source": [
    "top_data_df_small = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "cjdOMnsVYln_",
    "outputId": "f578642a-ba30-4596-b486-a159e2e0bc39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train genders\n",
      "0    139360\n",
      "1    139238\n",
      "Name: target, dtype: int64\n",
      "Value counts for Test genders\n",
      "1    15539\n",
      "0    15417\n",
      "Name: target, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "    index                                               text\n",
      "0   52967  Still scrubbing... looks like there's a third ...\n",
      "1  307438                               Now just a minute...\n",
      "2  243209                                       All I did...\n",
      "3  115665                                       I know that.\n",
      "4  138662  I'm okay.  Look, it's a big house. We needn't ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_train_test(top_data_df_small, test_size=0.1, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(top_data_df_small[['text']], \n",
    "                                                        top_data_df_small['target'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train genders\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test genders\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(top_data_df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Om1DxHwrBAkd"
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Oh5JqNqYhpRO",
    "outputId": "7134e9a9-97a9-44c7-ff1a-94b239c6493e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30956"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K1F7isK2v16u",
    "outputId": "b2816d28-9b71-4f30-dc2a-a25044d47778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30956"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6qnr7RpBjpX"
   },
   "outputs": [],
   "source": [
    "test_df['text'] = X_test['text']\n",
    "test_df['target'] = Y_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "2c_T7IyFh62o",
    "outputId": "01144e05-6f40-45d9-d2bd-2279599de41f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You've never been to a dance, have you?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Dudley there were more sides of the tracks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, I met someone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's you who's being hurt. By keeping it insid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't be dense. The party.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Don't you open them anymore?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You know what? It's Christmas Eve. And you loo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'd soon die.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yeah? See ya.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You know what?  I think you guys are all jealous.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0            You've never been to a dance, have you?       0\n",
       "1  In Dudley there were more sides of the tracks ...       0\n",
       "2                             Well, I met someone...       1\n",
       "3  It's you who's being hurt. By keeping it insid...       1\n",
       "4                         Don't be dense. The party.       1\n",
       "5                       Don't you open them anymore?       1\n",
       "6  You know what? It's Christmas Eve. And you loo...       1\n",
       "7                                      I'd soon die.       1\n",
       "8                                      Yeah? See ya.       1\n",
       "9  You know what?  I think you guys are all jealous.       0"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VhXr-hzhbWo"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "train_df['text'] = X_train['text']\n",
    "train_df['target'] = Y_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "83lncgHODKrr",
    "outputId": "bfd487e8-96ac-4ea7-f95b-4c405e32a852"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Still scrubbing... looks like there's a third ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now just a minute...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All I did...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I know that.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm okay.  Look, it's a big house. We needn't ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Still scrubbing... looks like there's a third ...       0\n",
       "1                               Now just a minute...       1\n",
       "2                                       All I did...       1\n",
       "3                                       I know that.       0\n",
       "4  I'm okay.  Look, it's a big house. We needn't ...       0"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyHIaaLBBvjl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3410JYZBz-W"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sb9qgJqZCD6G"
   },
   "outputs": [],
   "source": [
    "class DataFrameDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.target if not is_test else None\n",
    "            text = row.text\n",
    "            examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        data_field = fields\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
    "        if val_df is not None:\n",
    "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjxl97h0CHp1"
   },
   "outputs": [],
   "source": [
    "fields = [('text',TEXT), ('label',LABEL)]\n",
    "train_ds, test_ds = DataFrameDataset.splits(fields, train_df=train_df, val_df=test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "24qfffNWCQMV",
    "outputId": "1872daf6-d68c-40dd-99be-7cac87cd0243"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n",
      "100%|█████████▉| 399578/400000 [00:36<00:00, 10110.04it/s]"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = len(X_train)\n",
    "\n",
    "TEXT.build_vocab(train_ds, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = 'glove.6B.200d',\n",
    "                 unk_init = torch.Tensor.zero_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UztZBl8Dh2s"
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrG_oTcyDiSf"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, test_ds), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gg7jD3OCDjzO"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 25\n",
    "learning_rate = 0.001\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 4\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_HiYtQpDlx1"
   },
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        # text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        # output = [sent len, batch size, hid dim * num directions]\n",
    "        # output over padding tokens are zero tensors\n",
    "        \n",
    "        # hidden = [num layers * num directions, batch size, hid dim]\n",
    "        # cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        # and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        output = self.fc1(hidden)\n",
    "        output = self.dropout(self.fc2(output))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czSI_FLXDqHd"
   },
   "outputs": [],
   "source": [
    "#creating instance of our LSTM_net class\n",
    "\n",
    "model = LSTM_net(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ZVqWGFzbDsAO",
    "outputId": "1a877411-1533-4142-a7bc-c7c63b28ab30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54837, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1229,  0.5804, -0.0696,  ..., -0.0392, -0.1624, -0.0967],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "C3IRM8sFDto1",
    "outputId": "81b85175-70ff-42ba-84b1-0b9e01217426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1229,  0.5804, -0.0696,  ..., -0.0392, -0.1624, -0.0967],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6N-4kQR0DxNF",
    "outputId": "b5d1360f-6ca0-4509-83e1-4e424cb590b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399578/400000 [00:50<00:00, 10110.04it/s]"
     ]
    }
   ],
   "source": [
    "model.to(device) #CNN to GPU\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF-FRBjVD6Gz"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HG6cPE2CD6gN"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        # for a in text_lengths:\n",
    "        #   if(a.item <= 0):\n",
    "        #     text_lengths.remove\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upm_H3RxD75G"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RtJgYjKdD9de",
    "outputId": "fab7c195-b2c3-4793-e7aa-96fd2f453740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "\tTrain Loss: 0.682 | Train Acc: 53.76%\n",
      "\tVal Loss: 0.654 | Val. Acc: 61.93%\n",
      "\n",
      "\n",
      "Epoch 1 :\n",
      "\tTrain Loss: 0.653 | Train Acc: 57.75%\n",
      "\tVal Loss: 0.623 | Val. Acc: 64.64%\n",
      "\n",
      "\n",
      "Epoch 2 :\n",
      "\tTrain Loss: 0.631 | Train Acc: 59.12%\n",
      "\tVal Loss: 0.611 | Val. Acc: 66.00%\n",
      "\n",
      "\n",
      "Epoch 3 :\n",
      "\tTrain Loss: 0.613 | Train Acc: 60.35%\n",
      "\tVal Loss: 0.592 | Val. Acc: 67.03%\n",
      "\n",
      "\n",
      "Epoch 4 :\n",
      "\tTrain Loss: 0.597 | Train Acc: 61.25%\n",
      "\tVal Loss: 0.583 | Val. Acc: 67.90%\n",
      "\n",
      "\n",
      "Epoch 5 :\n",
      "\tTrain Loss: 0.584 | Train Acc: 62.07%\n",
      "\tVal Loss: 0.569 | Val. Acc: 69.15%\n",
      "\n",
      "\n",
      "Epoch 6 :\n",
      "\tTrain Loss: 0.571 | Train Acc: 62.75%\n",
      "\tVal Loss: 0.557 | Val. Acc: 69.82%\n",
      "\n",
      "\n",
      "Epoch 7 :\n",
      "\tTrain Loss: 0.560 | Train Acc: 63.45%\n",
      "\tVal Loss: 0.549 | Val. Acc: 70.09%\n",
      "\n",
      "\n",
      "Epoch 8 :\n",
      "\tTrain Loss: 0.549 | Train Acc: 64.21%\n",
      "\tVal Loss: 0.543 | Val. Acc: 71.05%\n",
      "\n",
      "\n",
      "Epoch 9 :\n",
      "\tTrain Loss: 0.540 | Train Acc: 64.65%\n",
      "\tVal Loss: 0.533 | Val. Acc: 71.84%\n",
      "\n",
      "\n",
      "Epoch 10 :\n",
      "\tTrain Loss: 0.530 | Train Acc: 65.06%\n",
      "\tVal Loss: 0.541 | Val. Acc: 71.63%\n",
      "\n",
      "\n",
      "Epoch 11 :\n",
      "\tTrain Loss: 0.522 | Train Acc: 65.65%\n",
      "\tVal Loss: 0.527 | Val. Acc: 72.99%\n",
      "\n",
      "\n",
      "Epoch 12 :\n",
      "\tTrain Loss: 0.515 | Train Acc: 66.21%\n",
      "\tVal Loss: 0.528 | Val. Acc: 73.73%\n",
      "\n",
      "\n",
      "Epoch 13 :\n",
      "\tTrain Loss: 0.507 | Train Acc: 66.57%\n",
      "\tVal Loss: 0.526 | Val. Acc: 74.15%\n",
      "\n",
      "\n",
      "Epoch 14 :\n",
      "\tTrain Loss: 0.500 | Train Acc: 66.96%\n",
      "\tVal Loss: 0.532 | Val. Acc: 74.10%\n",
      "\n",
      "\n",
      "Epoch 15 :\n",
      "\tTrain Loss: 0.492 | Train Acc: 67.41%\n",
      "\tVal Loss: 0.521 | Val. Acc: 74.87%\n",
      "\n",
      "\n",
      "Epoch 16 :\n",
      "\tTrain Loss: 0.487 | Train Acc: 67.55%\n",
      "\tVal Loss: 0.525 | Val. Acc: 75.37%\n",
      "\n",
      "\n",
      "Epoch 17 :\n",
      "\tTrain Loss: 0.481 | Train Acc: 67.96%\n",
      "\tVal Loss: 0.528 | Val. Acc: 75.61%\n",
      "\n",
      "\n",
      "Epoch 18 :\n",
      "\tTrain Loss: 0.476 | Train Acc: 68.25%\n",
      "\tVal Loss: 0.525 | Val. Acc: 76.35%\n",
      "\n",
      "\n",
      "Epoch 19 :\n",
      "\tTrain Loss: 0.469 | Train Acc: 68.72%\n",
      "\tVal Loss: 0.579 | Val. Acc: 76.22%\n",
      "\n",
      "\n",
      "Epoch 20 :\n",
      "\tTrain Loss: 0.465 | Train Acc: 68.85%\n",
      "\tVal Loss: 0.531 | Val. Acc: 76.76%\n",
      "\n",
      "\n",
      "Epoch 21 :\n",
      "\tTrain Loss: 0.462 | Train Acc: 69.07%\n",
      "\tVal Loss: 0.529 | Val. Acc: 76.86%\n",
      "\n",
      "\n",
      "Epoch 22 :\n",
      "\tTrain Loss: 0.457 | Train Acc: 69.30%\n",
      "\tVal Loss: 0.557 | Val. Acc: 77.80%\n",
      "\n",
      "\n",
      "Epoch 23 :\n",
      "\tTrain Loss: 0.454 | Train Acc: 69.43%\n",
      "\tVal Loss: 0.526 | Val. Acc: 77.83%\n",
      "\n",
      "\n",
      "Epoch 24 :\n",
      "\tTrain Loss: 0.449 | Train Acc: 69.70%\n",
      "\tVal Loss: 0.558 | Val. Acc: 77.63%\n",
      "\n",
      "\n",
      "time:3080.550\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "val_losses=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_iterator)\n",
    "    val_loss, valid_acc = evaluate(model, valid_iterator)\n",
    "    print(\"Epoch \" + str(epoch) + \" :\")\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\tVal Loss: {val_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print('\\n')\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    val_acc.append(valid_acc)\n",
    "    val_losses.append(val_loss)\n",
    "print(f'time:{time.time()-t:.3f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GenderClassifierLSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
