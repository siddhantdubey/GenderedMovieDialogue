{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torchtext import data\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "X_train = []\n",
    "X_train_vect = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "X_test_vect = []\n",
    "Y_test = []\n",
    "\n",
    "all_pos_tags = ['#', '$', \"''\", '(', ')', ',', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data/male_tagged_train.txt', encoding = 'charmap') as mtagged_train:\n",
    "    for line in mtagged_train:\n",
    "        line = str(line.strip())\n",
    "        line = ast.literal_eval(line)\n",
    "        train[tuple(line)] = 0\n",
    "\n",
    "with open(r'data/male_tagged_test.txt', encoding = 'charmap') as mtagged_test:\n",
    "    for line in mtagged_test:\n",
    "        line = str(line.strip())\n",
    "        line = ast.literal_eval(line)\n",
    "        test[tuple(line)] = 0\n",
    "\n",
    "with open(r'data/female_tagged_train.txt', encoding = 'charmap') as ftagged_train:\n",
    "    for line in ftagged_train:\n",
    "        line = str(line.strip())\n",
    "        line = ast.literal_eval(line)\n",
    "        train[tuple(line)] = 1\n",
    "        \n",
    "with open(r'data/female_tagged_test.txt', encoding = 'charmap') as ftagged_test:\n",
    "    for line in ftagged_test:\n",
    "        line = str(line.strip())\n",
    "        line = ast.literal_eval(line)\n",
    "        test[tuple(line)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys = list(train.keys())\n",
    "random.shuffle(train_keys)\n",
    "train_set =  [(key, train[key]) for key in train_keys]\n",
    "\n",
    "\n",
    "test_keys = list(test.keys())\n",
    "random.shuffle(test_keys)\n",
    "test_set= [(key, test[key]) for key in test_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_vect(x):\n",
    "    pos_dict = {key : 0 for key in all_pos_tags}\n",
    "    tag_list = []\n",
    "    for i in range(len(x)):\n",
    "        temp = x[i][1]\n",
    "        tag_list.append(temp)\n",
    "    for j in range(len(tag_list)):\n",
    "        pos_dict[tag_list[j]] += 1\n",
    "    \n",
    "    pos_vector = list(pos_dict.values())\n",
    "    total = sum(pos_vector)\n",
    "    pos_prop_vector = []\n",
    "\n",
    "    for k in range(len(pos_vector)):\n",
    "        pos_prop_vector.append(pos_vector[k] / total)\n",
    "    \n",
    "    out = np.array(pos_prop_vector)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_normalize(x):\n",
    "    m = max(x)\n",
    "    x_mod = []\n",
    "    for i in range(len(x)):\n",
    "        x_mod.append(x[i]/m)\n",
    "    return x_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_set)):\n",
    "    X_train.append(train_set[i][0])\n",
    "    Y_train.append(train_set[i][1])\n",
    "\n",
    "for j in range(len(test_set)):\n",
    "    X_test.append(test_set[j][0])\n",
    "    Y_test.append(test_set[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_indices = []\\nfor i in range(len(X_train)):\\n    if(len(X_train[i]) > 0):\\n        answer = True \\n    else:\\n        x_indices.append(i)\\n\\nfor index in sorted(x_indices, reverse=True):\\n    del X_train[index]\\n    del Y_train[index]\\n\\ny_indices = []\\nfor i in range(len(X_test)):\\n    if(len(X_test[i]) > 0):\\n        answer = True\\n    else:\\n        y_indices.append(i)\\n\\nfor index in sorted(y_indices, reverse=True):\\n    del X_test[index]\\n    del Y_test[index]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_indices = []\n",
    "for i in range(len(X_train)):\n",
    "    if(len(X_train[i]) > 0):\n",
    "        answer = True \n",
    "    else:\n",
    "        x_indices.append(i)\n",
    "\n",
    "for index in sorted(x_indices, reverse=True):\n",
    "    del X_train[index]\n",
    "    del Y_train[index]\n",
    "\n",
    "y_indices = []\n",
    "for i in range(len(X_test)):\n",
    "    if(len(X_test[i]) > 0):\n",
    "        answer = True\n",
    "    else:\n",
    "        y_indices.append(i)\n",
    "\n",
    "for index in sorted(y_indices, reverse=True):\n",
    "    del X_test[index]\n",
    "    del Y_test[index]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5505b11bd0db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr_to_vect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mX_test_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    a = str_to_vect(X_train[i])\n",
    "    a = vect_normalize(a)\n",
    "    X_train_vect.append(a)\n",
    "\n",
    "for j in range(len(X_test)):\n",
    "    b = str_to_vect(X_test[j])\n",
    "    b = vect_normalize(b)\n",
    "    X_test_vect.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for i in range(len(X_train_vect)):\n",
    "    X_train_vect[i] *= (10**n)\n",
    "\n",
    "for j in range(len(X_test_vect)):\n",
    "    X_test_vect[j] *= (10**n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_vect + X_test_vect\n",
    "Y = Y_train + Y_test\n",
    "df['pos'] = X_train_vect \n",
    "df['target'] = Y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_data(top_n = 30000):\n",
    "    top_data_df_male = df[df['target'] == 0].head(top_n)\n",
    "    top_data_df_female = df[df['target'] == 1].head(top_n)\n",
    "    data_df_small = pd.concat([top_data_df_male, top_data_df_female])\n",
    "    return data_df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_data_df_small = get_top_data(top_n=114250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_train_test(top_data_df_small, test_size=0.2, shuffle_state=True):\n",
    "    X_train_vect, X_test_vect, Y_train, Y_test = train_test_split(top_data_df_small[['pos']], \n",
    "                                                        top_data_df_small['target'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train genders\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test genders\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train_vect))\n",
    "    print(type(Y_train))\n",
    "    X_train_vect = X_train_vect.reset_index()\n",
    "    X_test_vect = X_test_vect.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train_vect.head())\n",
    "    return X_train_vect, X_test_vect, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "X_train_vect, X_test_vect, Y_train, Y_test = split_train_test(top_data_df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pos'] = X_test_vect['pos']\n",
    "test_df['target'] = Y_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "train_df['pos'] = X_train_vect['pos']\n",
    "train_df['target'] = Y_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df['pos'].to_numpy()\n",
    "train_x = np.stack(train_x)\n",
    "train_x_shape = train_x.shape\n",
    "#train_x = train_x.reshape((1, train_x_shape[0], train_x_shape[1]))\n",
    "#train_x.reshape(train_x_shape[0], train_x_shape[1], 1)\n",
    "train_x = train_x.astype('float32')\n",
    "train_x = torch.Tensor(train_x)\n",
    "train_x.type(torch.cuda.LongTensor)\n",
    "train_x = train_x.unsqueeze(dim=2)\n",
    "train_x = train_x.float()\n",
    "train_x = train_x.cuda()\n",
    "\n",
    "train_y = train_df['target'].to_numpy()\n",
    "train_y = np.stack(train_y)\n",
    "train_y_shape = train_y.shape\n",
    "#train_y.reshape(1, train_y_shape[0], train_y_shape[1])\n",
    "train_y = train_y.astype('int64')\n",
    "train_y = torch.Tensor(train_y)\n",
    "train_y.type(torch.cuda.LongTensor)\n",
    "train_y = train_y.unsqueeze(dim=1)\n",
    "train_y = train_y.long()\n",
    "train_y = train_y.cuda()\n",
    "\n",
    "test_x = test_df['pos'].to_numpy()\n",
    "test_x = np.stack(test_x)\n",
    "test_x_shape = test_x.shape\n",
    "#test_x = test_x.reshape((1, test_x_shape[0], test_x_shape[1]))\n",
    "#test_x.reshape(test_x_shape[0], test_x_shape[1], 1)\n",
    "test_x = test_x.astype('float32')\n",
    "test_x = torch.Tensor(test_x)\n",
    "test_x.type(torch.cuda.LongTensor)\n",
    "test_x = test_x.unsqueeze(dim=2)\n",
    "test_x = test_x.float()\n",
    "test_x = test_x.cuda()\n",
    "\n",
    "test_y = test_df['target'].to_numpy()\n",
    "test_y = np.stack(test_y)\n",
    "test_y_shape = test_y.shape\n",
    "#test_y.reshape(1, test_y_shape[0], test_y_shape[1])\n",
    "test_y = test_y.astype('int64')\n",
    "test_y = torch.Tensor(test_y)\n",
    "test_y = test_y.unsqueeze(dim=1)\n",
    "test_y = test_y.long()\n",
    "test_y = test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.type())\n",
    "print(train_y.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "train_dataset = torch.utils.data.DataLoader(train, batch_size = 200, shuffle = True)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "test_dataset = torch.utils.data.DataLoader(test, batch_size = 200, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print(len(train_dataset.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "n_iters = 300000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "    \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first = True).to(device)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    " \n",
    "        #out  = self.fc(out[:, -1, :])\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 10\n",
    "layer_dim = 1\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion = nn.BCEWithLogitsLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps to unroll\n",
    "seq_dim = 1\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (vectors, labels) in enumerate(train_dataset):\n",
    "        vectors = vectors.requires_grad_()\n",
    "        vectors = vectors.cuda()\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        \n",
    "        outputs = model(vectors)\n",
    "        outputs = outputs.to(device = device)\n",
    "        outputs = outputs.cuda()\n",
    "        \n",
    "        labels = labels.cuda()\n",
    "        labels = labels.float()\n",
    "        #labels = labels.unsqueeze(dim = -1)\n",
    "        labels = labels.to(device = device)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels).cuda()\n",
    "        #loss = criterion(outputs, labels)\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for vects, labs in test_dataset:\n",
    "                vectors = vectors.cuda()\n",
    "    \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(vects)\n",
    "                outputs = outputs.to(device = device)\n",
    "                outputs = outputs.cuda()\n",
    "                labs = labs.float()\n",
    "                labs = labs.squeeze(1)\n",
    "                # Get predictions from the maximum value\n",
    "                #_, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = outputs.data.squeeze(1)\n",
    "                print('Predicted: {}'.format(predicted))\n",
    "                predicted = torch.round(predicted)\n",
    "                predicted = predicted.float()\n",
    "                # Total number of labels\n",
    "                total += labs.size(0)\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labs).sum().item()\n",
    "                \n",
    "            #print('Predicted: {} '.format(predicted))\n",
    "            #print('Labels: {}'.format(labels))\n",
    "\n",
    "            #print(list(predicted.size()))\n",
    "            #print(list(labs.size()))\n",
    "            \n",
    "            #print(outputs.data)\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
