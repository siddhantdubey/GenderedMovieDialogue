{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "male = []\n",
    "female = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data/training_set.txt') as training:\n",
    "    for line in training:\n",
    "        line = line.strip()\n",
    "        lnum, chr_id, movie_id, chr_name, chr_gender, line_text, credit_list = line.split(\"+++$+++\")\n",
    "        chr_gender = chr_gender.strip()\n",
    "#         ss = sid.polarity_scores(line_text)\n",
    "#         sentiment = ss['compound']\n",
    "        if(chr_gender.lower() == \"m\"):\n",
    "            X_train.append(line_text)\n",
    "            male.append(line_text)\n",
    "            Y_train.append(0)\n",
    "        elif(chr_gender.lower() == \"f\"):\n",
    "            X_train.append(line_text)\n",
    "            female.append(line_text)\n",
    "            Y_train.append(1)\n",
    "\n",
    "\n",
    "with open(r'data/test_set.txt') as test:\n",
    "    for line in test:\n",
    "        line = line.strip()\n",
    "        lnum, chr_id, movie_id, chr_name, chr_gender, line_text, credit_list = line.split(\"+++$+++\")\n",
    "        chr_gender = chr_gender.strip()\n",
    "#         ss = sid.polarity_scores(line_text)\n",
    "#         sentiment = ss['compound']\n",
    "        if(chr_gender.lower() == \"m\"):\n",
    "            X_test.append(line_text)\n",
    "            male.append(line_text)\n",
    "            Y_test.append(0)\n",
    "        elif(chr_gender.lower() == \"f\"):\n",
    "            X_test.append(line_text)\n",
    "            female.append(line_text)\n",
    "            Y_test.append(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(r'data/validation_set.txt') as valid:\n",
    "    for line in valid:\n",
    "        line = line.strip()\n",
    "        lnum, chr_id, movie_id, chr_name, chr_gender, line_text, credit_list = line.split(\"+++$+++\")\n",
    "        chr_gender = chr_gender.strip()\n",
    "#         ss = sid.polarity_scores(line_text)\n",
    "#         sentiment = ss['compound']\n",
    "        if(chr_gender.lower() == \"m\"):\n",
    "            X_valid.append(line_text)\n",
    "            male.append(line_text)\n",
    "            Y_valid.append(0)\n",
    "        elif(chr_gender.lower() == \"f\"):\n",
    "            X_valid.append(line_text)\n",
    "            female.append(line_text)\n",
    "            Y_valid.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train + X_test + X_valid\n",
    "Y = Y_train + Y_test + Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(len(X)):\n",
    "  if(len(X[i]) > 0):\n",
    "    answer = True \n",
    "  else:\n",
    "    indices.append(i)\n",
    "\n",
    "for index in sorted(indices, reverse=True):\n",
    "    del X[index]\n",
    "    del Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X, Y = oversample.fit_resample(np.array(X).reshape(-1,1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for phrase in X:\n",
    "    a.append(phrase[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341536\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "X = a\n",
    "print(len(X))\n",
    "print(type(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = X\n",
    "df['target'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/tweets.csv', encoding=\"charmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1  815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2  815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3  815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4  815719230    False   finalized                   3     10/27/15 1:15   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male             1.0000        yes                    1.0   \n",
       "1    male             1.0000        yes                    1.0   \n",
       "2    male             0.6625        yes                    1.0   \n",
       "3    male             1.0000        yes                    1.0   \n",
       "4  female             1.0000        yes                    1.0   \n",
       "\n",
       "          created  ...                                       profileimage  \\\n",
       "0    12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
       "1   10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
       "2  11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
       "3   6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
       "4   4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
       "\n",
       "   retweet_count sidebar_color  \\\n",
       "0              0        FFFFFF   \n",
       "1              0        C0DEED   \n",
       "2              1        C0DEED   \n",
       "3              0        C0DEED   \n",
       "4              0             0   \n",
       "\n",
       "                                                text tweet_coord tweet_count  \\\n",
       "0  Robbie E Responds To Critics After Win Against...         NaN      110964   \n",
       "1  ÛÏIt felt like they were my friends and I was...         NaN        7471   \n",
       "2  i absolutely adore when louis starts the songs...         NaN        5617   \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...         NaN        1693   \n",
       "4  Watching Neighbours on Sky+ catching up with t...         NaN       31462   \n",
       "\n",
       "    tweet_created      tweet_id   tweet_location               user_timezone  \n",
       "0  10/26/15 12:40  6.587300e+17  main; @Kan1shk3                     Chennai  \n",
       "1  10/26/15 12:40  6.587300e+17              NaN  Eastern Time (US & Canada)  \n",
       "2  10/26/15 12:40  6.587300e+17           clcncl                    Belgrade  \n",
       "3  10/26/15 12:40  6.587300e+17    Palo Alto, CA  Pacific Time (US & Canada)  \n",
       "4  10/26/15 12:40  6.587300e+17              NaN                         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df['text']\n",
    "test_target = test_df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20050"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20050"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_data = []\n",
    "clean_test_target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_target)):\n",
    "    element = test_target[i]\n",
    "    text = test_data[i]\n",
    "    if element == \"male\":\n",
    "        clean_test_data.append(text)\n",
    "        clean_test_target.append(0)\n",
    "    elif element == \"female\":\n",
    "        clean_test_data.append(text)\n",
    "        clean_test_target.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12894"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12894"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[\"text\"]\n",
    "train_target = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = clean_test_data\n",
    "test_target = clean_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"classifier\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "bow_pipeline.fit(train_data, train_target)\n",
    "y_pred = bow_pipeline.predict(test_data)\n",
    "cr = classification_report(test_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.72      0.60      6194\n",
      "           1       0.60      0.39      0.47      6700\n",
      "\n",
      "    accuracy                           0.55     12894\n",
      "   macro avg       0.56      0.55      0.54     12894\n",
      "weighted avg       0.56      0.55      0.53     12894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "class SegmentFeaturizer:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.future_words = [\"tomorrow\", \"future\", \"futures\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_propernouns(doc):\n",
    "        segment = doc.text.lower().split()\n",
    "        count = 0 \n",
    "        num = 0\n",
    "        for token in doc:\n",
    "            if token.tag_ in ['NNP', 'NNPS']:\n",
    "                count+=1\n",
    "                num += 1\n",
    "            else:\n",
    "                num += 1\n",
    "        if(count == 0):\n",
    "            average = 0\n",
    "        else:\n",
    "            average = count/num\n",
    "        return average\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_words_before_main_verb(doc):\n",
    "        numbers = [0]\n",
    "        for sent in doc.sents:\n",
    "            main = [t for t in sent if t.dep_ == \"ROOT\"][0]\n",
    "            if main.pos_ == \"VERB\":\n",
    "                dist_to_init = main.i - sent[0].i\n",
    "                numbers.append(dist_to_init)\n",
    "        return np.mean(numbers)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_complex_clauses(doc):\n",
    "        embedded_elements_count = []\n",
    "        for sent in doc.sents:\n",
    "            n_embedded = len(\n",
    "                [t for t in sent if t.dep_ in {\"ccomp\", \"xcomp\", \"advcl\", \"dative\"}]\n",
    "            )\n",
    "            embedded_elements_count.append(n_embedded)\n",
    "        if len(embedded_elements_count) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.mean(embedded_elements_count)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mean_sentiment(doc):\n",
    "        return doc.sentiment\n",
    "    @staticmethod\n",
    "    def get_pronouns(doc):\n",
    "        count = 0\n",
    "        num = 0\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"PRON\":\n",
    "                count += 1\n",
    "                num += 1\n",
    "            else:\n",
    "                num += 1\n",
    "        if count == 0 or num == 0:\n",
    "            average = 0\n",
    "        else:\n",
    "            average = count/num\n",
    "        return average\n",
    "    @staticmethod\n",
    "    def get_female_pronouns(doc):\n",
    "        count = 0\n",
    "        num = 0\n",
    "        for token in doc:\n",
    "            if token.text.lower() in ['her', 'she', 'wife', 'girlfriend']:\n",
    "                count += 1\n",
    "                num += 1\n",
    "            else:\n",
    "                num+=1\n",
    "        if count == 0 or num == 0:\n",
    "            average = 0\n",
    "        else:\n",
    "            average = count/num\n",
    "        return average\n",
    "    @staticmethod\n",
    "    def get_male_pronouns(doc):\n",
    "        count = 0\n",
    "        num = 0\n",
    "        \n",
    "        for token in doc:\n",
    "            if token.text.lower() in ['he', 'him', 'husband', 'honey', 'his', 'boyfriend']:\n",
    "                count += 1\n",
    "                num += 1\n",
    "            else:\n",
    "                num += 1\n",
    "        if count == 0 or num == 0:\n",
    "            average = 0\n",
    "        else:\n",
    "            average = count/num\n",
    "        return average\n",
    "    def get_swear_words(doc):\n",
    "        count = 0\n",
    "        num = 0\n",
    "        for token in doc:\n",
    "            if token.lemma_.lower() in [\"fuck\", \"shit\", \"bitch\", \"hell\", \"asshole\", \"ass\"]:\n",
    "                count += 1\n",
    "                num += 1\n",
    "            else:\n",
    "                num += 1\n",
    "        if count == 0 or num == 0:\n",
    "            average = 0\n",
    "        else:\n",
    "            average = count/num\n",
    "        return average\n",
    "    # putting it all together!\n",
    "    def featurize(self, segments):\n",
    "        feature_dicts = []\n",
    "        docs = self.nlp.pipe(segments)\n",
    "        for doc in docs:\n",
    "            feature_dict = {\n",
    "                \n",
    "                \"n_propernouns\": self.count_propernouns(doc),\n",
    "                \"n_words_before_main_verb\": self.get_n_words_before_main_verb(doc),\n",
    "                \"n_complex_clauses\": self.get_n_complex_clauses(doc),\n",
    "                \"mean_sentiment\": self.get_mean_sentiment(doc),\n",
    "                \"n_pronouns\": self.get_pronouns(doc),\n",
    "                \"n_male_pronouns\": self.get_male_pronouns(doc),\n",
    "                \"n_female_pronouns\": self.get_female_pronouns(doc)\n",
    "                \n",
    "            }\n",
    "            feature_dicts.append(feature_dict)\n",
    "        return feature_dicts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "segment_featurizer = SegmentFeaturizer()\n",
    "class CustomLinguisticFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        return segment_featurizer.featurize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"stats\", CustomLinguisticFeatureTransformer()),\n",
    "        (\"dict_vect\", DictVectorizer()),\n",
    "        (\"classifier\", LinearSVC()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "manual_pipeline.fit(train_data, train_target)\n",
    "y_pred = manual_pipeline.predict(test_data)\n",
    "crmanual = classification_report(test_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.87      0.62      6194\n",
      "           1       0.54      0.15      0.23      6700\n",
      "\n",
      "    accuracy                           0.49     12894\n",
      "   macro avg       0.51      0.51      0.43     12894\n",
      "weighted avg       0.52      0.49      0.42     12894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(crmanual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"tfidf\", TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='utf-8', ngram_range=(1, 3), stop_words='english')),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"stats\", CustomLinguisticFeatureTransformer()),\n",
    "        (\"dict_vect\", DictVectorizer()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SpacyVectorTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-fc10f3179b13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m embedding_pipeline = Pipeline(\n\u001b[0;32m      2\u001b[0m     steps=[\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"mean_embeddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpacyVectorTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"reduce_dim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SpacyVectorTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"mean_embeddings\", SpacyVectorTransformer(nlp)),\n",
    "        (\"reduce_dim\", TruncatedSVD(50)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        (\"bow\", bow_pipeline),\n",
    "        (\"manual\", manual_pipeline),\n",
    "    ]\n",
    ")\n",
    "final_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", combined_features),\n",
    "        (\"classifier\",LinearSVC()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "final_pipeline.fit(train_data, train_target)\n",
    "y_pred = final_pipeline.predict(test_data)\n",
    "finalcrmultinomial = classification_report(test_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59      6194\n",
      "           1       0.55      0.33      0.41      6700\n",
      "\n",
      "    accuracy                           0.51     12894\n",
      "   macro avg       0.52      0.52      0.50     12894\n",
      "weighted avg       0.53      0.51      0.50     12894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(finalcrmultinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25577"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
